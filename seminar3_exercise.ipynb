{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminar3_exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzTJLLxafgt1",
        "colab_type": "text"
      },
      "source": [
        "# 1. Pre-processing - Сургалтын процессд зориулан датаг бэлтгэх\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlLbPZcKBX8F",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Preprocessing-ийн өмнөх хэсэг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0vk8Cg3lnMM",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1. Шаардлагатай сангуудыг импортлох"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUF9NRjCltpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn            # Neural Network-той холбоотой бүхнийг агуулна.\n",
        "from torch import optim         # Оновчлолын алгоритмуудыг агуулна.\n",
        "import torch.nn.functional as F # Функциональ алгоритмуудыг агуулна.\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvVvk_2LkpkM",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.2. GPU mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73jC8QlDkuQ7",
        "colab_type": "text"
      },
      "source": [
        "**Edit > Notebook Settings > Hardware accelerator** хэсгийг **GPU** болгож өөрчлөх\n",
        "\n",
        "(Сургалтын процессыг GPU ашиглан сургавал дан CPU дээр ажиллуулснаас хэд дахин хурдан ажиллана.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5zC-BQBlVRz",
        "colab_type": "code",
        "outputId": "7f6be66b-06ee-4be9-ca84-834b6d9e553a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P_Rt0Bt5IpX",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.3. Датаг унших\n",
        "\n",
        "\"!\" тэмдэг ашиглан shell комманд ажиллуулж болох ба \"{}\" ашиглан shell комманд дотроо python variable оруулж болдог "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nELBJM0oLdCN",
        "colab_type": "code",
        "outputId": "9a6163bc-72b6-475c-a310-4acaac150dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "filename = \"book.txt\"\n",
        "!wget -O {filename} \"https://drive.google.com/uc?export=download&id=1uzTJe8PPS0t116KcC9lGlvdlmO6guKR1\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-24 04:30:08--  https://drive.google.com/uc?export=download&id=1uzTJe8PPS0t116KcC9lGlvdlmO6guKR1\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.212.138, 172.217.212.139, 172.217.212.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.212.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0g-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/p8imisp6oqu5etovv8fqdriuk99qnftp/1563940800000/13980977719275995798/*/1uzTJe8PPS0t116KcC9lGlvdlmO6guKR1?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2019-07-24 04:30:09--  https://doc-0g-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/p8imisp6oqu5etovv8fqdriuk99qnftp/1563940800000/13980977719275995798/*/1uzTJe8PPS0t116KcC9lGlvdlmO6guKR1?e=download\n",
            "Resolving doc-0g-00-docs.googleusercontent.com (doc-0g-00-docs.googleusercontent.com)... 108.177.112.132, 2607:f8b0:4001:c12::84\n",
            "Connecting to doc-0g-00-docs.googleusercontent.com (doc-0g-00-docs.googleusercontent.com)|108.177.112.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘book.txt’\n",
            "\n",
            "book.txt                [ <=>                ]   2.09M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-07-24 04:30:09 (189 MB/s) - ‘book.txt’ saved [2187725]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC-RYYhbVKOC",
        "colab_type": "code",
        "outputId": "edf07c66-06a1-4142-eeae-9d7a755784d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mnt_text = None \n",
        "with open(filename) as f:\n",
        "  mnt_text = f.read()\n",
        "  \n",
        "print(\"Number of chars: \", len(mnt_text))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of chars:  1206907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le_7ECvqkW0D",
        "colab_type": "code",
        "outputId": "84d35e5f-72cc-4bac-b00d-2caad56441ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(mnt_text[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "МОНГОЛЫН ӨГҮҮЛЛЭГИЙН\n",
            "ЦОМОРЛИГ\n",
            "Энэхүү цоморлигт 1990 – ээд оноос хойш туурвигдсан утга зохиолын тэмцэ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRiHeNvk6REv",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6ye0MPxsz__",
        "colab_type": "text"
      },
      "source": [
        "Датаг сургалтанд зориулан бэлтгэнэ. Ингэснээр алдаа гарах нь бага, мөн илүү үнэмшилтэй үр дүнд хүрнэ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfJQYIfFrhbX",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1. Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTXvcQ7WrCMF",
        "colab_type": "text"
      },
      "source": [
        "Датаг токенууд болгон салгана. \n",
        "\n",
        "(Бидний тохиолдолд, үсэг бүрээр нь салгана) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo-zpi9zmNz0",
        "colab_type": "code",
        "outputId": "13da3d31-78b7-41bb-e061-f672bc09b26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# encode the text and map each character to an integer and vice versa\n",
        "\n",
        "text = mnt_text[:]\n",
        "\n",
        "# set of all characters (which is become vocabulary of our model)\n",
        "chars = list(set(text))\n",
        "print(\"Vocab size: \", len(chars))\n",
        "print(\"Sample: \", chars[:10])\n",
        "\n",
        "# 1. int2char, which maps integers to characters\n",
        "int2char = { i:ch for i, ch in enumerate(chars) }\n",
        "\n",
        "# 2. char2int, which maps characters to unique integers\n",
        "char2int = { ch:i for i,ch in enumerate(chars) }\n",
        "\n",
        "# encode the text\n",
        "encoded = np.array([char2int[ch] for ch in text])\n",
        "print(\"Encode: \", encoded[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size:  127\n",
            "Sample:  ['м', 'Й', 'N', 'o', 'l', '.', 's', '”', '-', '\"']\n",
            "Encode:  [ 66  72  13 118  72  98 121  13 126  94]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAM6pf2Qb8-R",
        "colab_type": "code",
        "outputId": "1898a504-6d03-4c49-a691-1bb2a4d82a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(text[:10])\n",
        "encoded[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "МОНГОЛЫН Ө\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66,  72,  13, 118,  72,  98, 121,  13, 126,  94])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqpS8Z7AzAAz",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2. Encoding the characters\n",
        "\n",
        "useful functions:\n",
        "\n",
        "```\n",
        ">>> a = [[3 5 4], [4 5 7]]\n",
        ">>> a.flatten() \n",
        "[3 5 4 4 5 7]\n",
        ">>> np.arange(3)\n",
        "array([0, 1, 2])\n",
        ">>> a.reshape(1, 6)\n",
        "[3 5 4 4 5 7]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg5hJA8sxmtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "  \n",
        "  # TODO: implement one-hot encoding\n",
        "  \n",
        "  # Initialize the encoded array (with zeros) size = (arr.size x n_labels)\n",
        "  \n",
        "  # Fill the appropriate elements with ones\n",
        "  \n",
        "  # Finally reshape it to get back to the original array\n",
        "  \n",
        "  return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNKz-Oi9xp2O",
        "colab_type": "code",
        "outputId": "4f54bc2f-5dc3-43d4-e6dc-95d6aa669a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# check that the function works as expected\n",
        "test_seq = np.array([[3, 5, 4], [4, 5, 7]])\n",
        "one_hot = one_hot_encode(test_seq, 8)\n",
        "print(one_hot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRRXVsX5eIdE",
        "colab_type": "text"
      },
      "source": [
        "Дараахь хэлбэртэй харагдана.\n",
        "```\n",
        "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
        "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
        "  [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
        "\n",
        " [[0. 0. 0. 0. 1. 0. 0. 0.]\n",
        "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
        "  [0. 0. 0. 0. 0. 0. 0. 1.]]]\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Yxv5mMzeDg",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.3. Making training mini-batches\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/recurrent-neural-networks/char-rnn/assets/sequence_batching%401x.png\" width=500 />\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhdgSQybq6kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "  '''Create a generator that returns batches of size\n",
        "        \n",
        "        batch_size x seq_length \n",
        "     \n",
        "     from arr.\n",
        "     \n",
        "     Arguments\n",
        "     ---------\n",
        "     arr:         Array you want to make batches from\n",
        "     batch_size:  Batch size, the number of sequences per batch\n",
        "     seq_length:  Number of encoded chars in a sequence\n",
        "  '''\n",
        "  \n",
        "  batch_size_total = batch_size * seq_length\n",
        "  \n",
        "  # TODO: Make mini-batches\n",
        "  \n",
        "  # TODO: Get the number of batches we can make\n",
        "  n_batches =\n",
        "  \n",
        "  # TODO: Keep only enough characters to make full batches\n",
        "  arr =\n",
        "  \n",
        "  # TODO: Reshape into batch_size rows\n",
        "  arr = \n",
        "  \n",
        "  for n in range(0, arr.shape[1], seq_length):\n",
        "    # The features\n",
        "    x = arr[:, n:n+seq_length]\n",
        "    \n",
        "    # The targets, shifted by one\n",
        "    y = np.zeros_like(x)\n",
        "    \n",
        "    try:\n",
        "      y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "    except IndexError:\n",
        "      y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "    yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaF0tw0ivEHe",
        "colab_type": "code",
        "outputId": "2c662d79-091f-4eea-9690-bd4ab8be290e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "batches = get_batches(encoded, 8, 50)\n",
        "x, y = next(batches)\n",
        "\n",
        "print('x\\n', x[:3, :10])\n",
        "print('\\ny\\n', y[:3, :10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x\n",
            " [[ 66  72  13 118  72  98 121  13 126  94]\n",
            " [103  24  14  31  24 112  44 126  31  24]\n",
            " [106  27 106  84  35 106  48 126  83 101]]\n",
            "\n",
            "y\n",
            " [[ 72  13 118  72  98 121  13 126  94 118]\n",
            " [ 24  14  31  24 112  44 126  31  24  85]\n",
            " [ 27 106  84  35 106  48 126  83 101   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtBLCaxleaSS",
        "colab_type": "text"
      },
      "source": [
        "Output should looks like:\n",
        "```\n",
        "x\n",
        " [[ 66  72  13 118  72  98 121  13 126  94]\n",
        " [103  24  14  31  24 112  44 126  31  24]\n",
        " [106  27 106  84  35 106  48 126  83 101]]\n",
        "\n",
        "y\n",
        " [[ 72  13 118  72  98 121  13 126  94 118]\n",
        " [ 24  14  31  24 112  44 126  31  24  85]\n",
        " [ 27 106  84  35 106  48 126  83 101   0]]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE9RkCEM_qL6",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. Train, test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6C66U9G_pev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_test(data, validation_frac=0.1):\n",
        "    \n",
        "    # TODO: split data by validation fraction (validation_frac)\n",
        "    length =\n",
        "    \n",
        "    train, val_data = \n",
        "    \n",
        "    return train, val_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eegYPL2yrza",
        "colab_type": "text"
      },
      "source": [
        "# 2. Single layer RNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVpJL3tEiKSk",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Model Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stKSLRB3CyfB",
        "colab_type": "text"
      },
      "source": [
        "Simple RNN structure \n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" width=600 />\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCrmL0k9Y8M0",
        "colab_type": "text"
      },
      "source": [
        "Custom implementation: https://gist.github.com/karpathy/d4dee566867f8291f086"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIcfoYER4IZS",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://www.di.ens.fr/~lelarge/dldiy/slides/lecture_8/images/char_rnn_2.png\" width=500 />\n",
        "\n",
        "Layer definition:\n",
        "\n",
        " - input layer --> hidden layer\n",
        "```\n",
        "self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "```\n",
        "\n",
        "- hidden layer --> output layer  \n",
        "```\n",
        "self.fc = nn.Linear(hidden_dim, output_size)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTmc8WsTJ8bI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class SingleRNN(nn.Module):\n",
        "    def __init__(self, tokens, n_hidden=256):\n",
        "        super().__init__()\n",
        "        self.n_hidden = n_hidden\n",
        "\n",
        "        # creating character dictionaries\n",
        "        self.chars = list(set(tokens))\n",
        "        self.int2char = { i:ch for i, ch in enumerate(self.chars) }\n",
        "        self.char2int = { ch:i for i, ch in enumerate(self.chars) }\n",
        "        self.in_out_dim = len(self.chars)\n",
        "        \n",
        "        # TODO: RNN layer\n",
        "        self.rnn =\n",
        "        \n",
        "        # TODO: last, fully-connected layer\n",
        "        self.fc = \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \n",
        "        # TODO: get RNN outputs\n",
        "        r_out, hidden = \n",
        "       \n",
        "        # shape output to be (batch_size * seq_length, n_hidden)\n",
        "        r_out = r_out.contiguous().view(-1, self.n_hidden)  \n",
        "        \n",
        "        # TODO: get final output Full Connected\n",
        "        output = \n",
        "        \n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "      # TODO: shape of (Layer, batch_size, hidden_dim)\n",
        "      return torch.zeros(...)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-CEWf1IFL6i",
        "colab_type": "text"
      },
      "source": [
        "## 2.2. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bKnGKijOnrw",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameters:**\n",
        "\n",
        " - n_hidden     - hidden давхаргын нейроны тоо\n",
        " - batch_size  - Нэг удаагийн урсгалаар нэгэн зэрэг хэдэн дарааллыг сургахыг заана.\n",
        " - seq_length  - Network-ийн сургалтын 1 \"дарааллын\" урт. Дараалал урт байх тусам илүү сайн сурна. \n",
        " - lr                   - Learning rate\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPVUdvaugdUA",
        "colab_type": "text"
      },
      "source": [
        "**Cross entropy loss**: \n",
        "\n",
        "nn.LogSoftmax() болон nn.NLLLoss()-ийг нэгтгэсэн гэж хэлж болно.\n",
        "\n",
        "\\begin{align*}\n",
        "L_{cross-entropy}(\\hat{y}, y) = -\\sum y_ilog(\\hat{y_i})\n",
        "\\end{align*}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w5jRarH8UPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainRNN(rnn, data, epochs=10, batch_size=10, seq_length=20, lr=0.001, val_frac=0.1):\n",
        "  \n",
        "  train_data, val_data = split_train_test(data, 0.1)\n",
        "  \n",
        "  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  train_loss_graph = []\n",
        "  val_loss_graph = []\n",
        "  \n",
        "  for e in range(epochs):\n",
        "    # init hidden state\n",
        "    hidden_state = rnn.init_hidden(batch_size)\n",
        "\n",
        "    counter = 0\n",
        "    \n",
        "    for x, y in get_batches(data, batch_size, seq_length):\n",
        "      loss = 0\n",
        "\n",
        "      x = one_hot_encode(x, len(rnn.chars))\n",
        "\n",
        "      inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "      # TODO: Forward propagation\n",
        "      output, hs = \n",
        "\n",
        "      rnn.zero_grad()\n",
        "\n",
        "      # TODO: Алдаа бодох criterion ашиглана\n",
        "      loss = \n",
        "\n",
        "      # Backward propagation\n",
        "      loss.backward(retain_graph=True)\n",
        "\n",
        "      optimizer.step()\n",
        "      \n",
        "      #nn.utils.clip_grad_norm_(rnn.parameters(), 5)\n",
        "      \n",
        "      hidden_state = hs.data\n",
        "\n",
        "      counter += 1\n",
        "    \n",
        "    train_loss_graph.append(\n",
        "        loss.item()\n",
        "    )\n",
        "    val_loss_graph.append(\n",
        "        validateRNN(\n",
        "            rnn,\n",
        "            val_data,\n",
        "            batch_size,\n",
        "            seq_length,\n",
        "            criterion,\n",
        "            len(rnn.chars),\n",
        "            loss,\n",
        "            counter,\n",
        "            e\n",
        "        )\n",
        "    )\n",
        "  plt.plot(val_loss_graph)\n",
        "  plt.plot(train_loss_graph)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIjFeylV4kPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateRNN(net, val_data, batch_size, seq_length, criterion, n_chars, loss, counter, e):\n",
        "    # Get validation loss\n",
        "    val_h = net.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "      \n",
        "        x = one_hot_encode(x, n_chars)\n",
        "        x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "        inputs, targets = x, y\n",
        "        \n",
        "        output, val_h = net(inputs, val_h)\n",
        "        \n",
        "        val_loss = criterion(output, targets.flatten())\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "          \"Step: {}...\".format(counter),\n",
        "          \"Loss: {:.4f}...\".format(loss.item()),\n",
        "          \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
        "    return np.mean(val_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co8OmEfEdFic",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Network ажиллуулах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7UGR76m8i2W",
        "colab_type": "code",
        "outputId": "18513367-25de-44b3-b7ba-6d15e1ace87e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "txt = text[:2000]\n",
        "seq_length = 20\n",
        "hidden_dim = 40\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "\n",
        "\n",
        "rnn = SingleRNN(txt, hidden_dim)\n",
        "\n",
        "encoded = np.array([rnn.char2int[ch] for ch in txt])\n",
        "\n",
        "print(rnn)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SingleRNN(\n",
            "  (rnn): RNN(69, 40, batch_first=True)\n",
            "  (fc): Linear(in_features=40, out_features=69, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "315mNcLnDljT",
        "colab_type": "code",
        "outputId": "53ccae36-2375-402a-97b2-d05e4959e770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        }
      },
      "source": [
        "trainRNN(rnn, encoded, epochs=epochs, batch_size=batch_size, seq_length=seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30... Step: 10... Loss: 4.1332... Val Loss: 4.1295\n",
            "Epoch: 2/30... Step: 10... Loss: 3.9735... Val Loss: 3.9638\n",
            "Epoch: 3/30... Step: 10... Loss: 3.7329... Val Loss: 3.7364\n",
            "Epoch: 4/30... Step: 10... Loss: 3.5914... Val Loss: 3.6303\n",
            "Epoch: 5/30... Step: 10... Loss: 3.5391... Val Loss: 3.6156\n",
            "Epoch: 6/30... Step: 10... Loss: 3.5218... Val Loss: 3.6151\n",
            "Epoch: 7/30... Step: 10... Loss: 3.5160... Val Loss: 3.6092\n",
            "Epoch: 8/30... Step: 10... Loss: 3.5109... Val Loss: 3.5999\n",
            "Epoch: 9/30... Step: 10... Loss: 3.5040... Val Loss: 3.5896\n",
            "Epoch: 10/30... Step: 10... Loss: 3.4945... Val Loss: 3.5793\n",
            "Epoch: 11/30... Step: 10... Loss: 3.4833... Val Loss: 3.5691\n",
            "Epoch: 12/30... Step: 10... Loss: 3.4706... Val Loss: 3.5580\n",
            "Epoch: 13/30... Step: 10... Loss: 3.4564... Val Loss: 3.5455\n",
            "Epoch: 14/30... Step: 10... Loss: 3.4405... Val Loss: 3.5314\n",
            "Epoch: 15/30... Step: 10... Loss: 3.4221... Val Loss: 3.5153\n",
            "Epoch: 16/30... Step: 10... Loss: 3.4008... Val Loss: 3.4966\n",
            "Epoch: 17/30... Step: 10... Loss: 3.3761... Val Loss: 3.4750\n",
            "Epoch: 18/30... Step: 10... Loss: 3.3475... Val Loss: 3.4503\n",
            "Epoch: 19/30... Step: 10... Loss: 3.3148... Val Loss: 3.4224\n",
            "Epoch: 20/30... Step: 10... Loss: 3.2778... Val Loss: 3.3912\n",
            "Epoch: 21/30... Step: 10... Loss: 3.2369... Val Loss: 3.3567\n",
            "Epoch: 22/30... Step: 10... Loss: 3.1924... Val Loss: 3.3179\n",
            "Epoch: 23/30... Step: 10... Loss: 3.1420... Val Loss: 3.2703\n",
            "Epoch: 24/30... Step: 10... Loss: 3.0695... Val Loss: 3.1912\n",
            "Epoch: 25/30... Step: 10... Loss: 3.0048... Val Loss: 3.1487\n",
            "Epoch: 26/30... Step: 10... Loss: 2.9559... Val Loss: 3.1153\n",
            "Epoch: 27/30... Step: 10... Loss: 2.9126... Val Loss: 3.0851\n",
            "Epoch: 28/30... Step: 10... Loss: 2.8717... Val Loss: 3.0466\n",
            "Epoch: 29/30... Step: 10... Loss: 2.8310... Val Loss: 3.0150\n",
            "Epoch: 30/30... Step: 10... Loss: 2.7920... Val Loss: 2.9857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCxsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB9NMEXAVhNP",
        "colab_type": "text"
      },
      "source": [
        "## 2.4. Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLCglcNiSCzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(rnn, char, h=None, top_k=None):\n",
        "  \n",
        "  # tensor inputs\n",
        "  x = np.array([[rnn.char2int[char]]])\n",
        "  x = one_hot_encode(x, len(rnn.chars))\n",
        "  inputs = torch.from_numpy(x)\n",
        "  \n",
        "  # get the output of the model\n",
        "  out, h = rnn.forward(inputs, h)\n",
        "  \n",
        "  # get the character probabilities\n",
        "  p = F.softmax(out, dim=1).data\n",
        "  \n",
        "  # get top characters\n",
        "  if top_k is None:\n",
        "    top_ch = np.arange(len(rnn.chars))\n",
        "  else:\n",
        "    p, top_ch = p.topk(top_k) # topk gets top likely next characters\n",
        "    top_ch = top_ch.numpy().squeeze()\n",
        "    \n",
        "  # select the likely next character with some element of randomness\n",
        "  p = p.numpy().squeeze()\n",
        "  char = np.random.choice(top_ch, p=p/p.sum())\n",
        "  \n",
        "  # return the encoded value of the predicted char and the hidden state\n",
        "  return rnn.int2char[char], h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObfFkn10avYg",
        "colab_type": "text"
      },
      "source": [
        "## 2.5. Priming and generating text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OKR8MSzSG64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(rnn, size, prime='байна', top_k=None):\n",
        "    \n",
        "  # First off, run through the prime characters\n",
        "  chars = [ch for ch in prime]\n",
        "  h = rnn.init_hidden(1)\n",
        "  for ch in prime:\n",
        "    char, h = predict(rnn, ch, h, top_k=top_k)\n",
        "    \n",
        "  chars.append(char)\n",
        "  \n",
        "  # Now pass in the previous character and get a new one\n",
        "  for ii in range(size):\n",
        "    char, h = predict(rnn, chars[-1], h, top_k=top_k)\n",
        "    chars.append(char)\n",
        "    \n",
        "  return ''.join(chars)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVLEqzeSSP9O",
        "colab_type": "code",
        "outputId": "304d0772-ccb8-4410-e2ae-7ea8019e2c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sample(rnn, 100, prime='Тэмүүжин', top_k=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Тэмүүжин бэн бай  болин тарлар иэр ар болон зийнэн аор ол оолэн тэл анг ан оол хиннан болин  олол агголан бол\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2al6xvui_ERO",
        "colab_type": "text"
      },
      "source": [
        "# 3. 2-layer LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAGxVTWTARV7",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/recurrent-neural-networks/char-rnn/assets/charRNN%400.5x.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUTQoushxBoq",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. Model Class "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRqtpcgCbzSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "  def __init__(self, tokens, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
        "    super().__init__()\n",
        "    self.drop_prob = drop_prob\n",
        "    self.n_layers = n_layers\n",
        "    self.n_hidden = n_hidden\n",
        "    self.lr = lr\n",
        "    \n",
        "    # creating character dictionaries\n",
        "    self.chars = tokens\n",
        "    self.int2char = dict(enumerate(self.chars))\n",
        "    self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "    \n",
        "    # Define the layers of the model\n",
        "    \n",
        "    # LSTM\n",
        "    self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
        "                        dropout=drop_prob, batch_first=True)\n",
        "    # Dropout layer\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    \n",
        "    # Final, fully-connected output layer\n",
        "    self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "    \n",
        "  def forward(self, x, hidden):\n",
        "    ''' Forward pass through the network.\n",
        "    These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "    \n",
        "    # Get the outputs and the new hidden state from the LSTM\n",
        "    r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "    out = self.dropout(r_output)\n",
        "    \n",
        "    # Stack up LSTM outputs using view\n",
        "    # you may need to use contiguous to reshape the output\n",
        "    out = out.contiguous().view(-1, self.n_hidden)\n",
        "    # put x through the fully-connected layer\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    # return the final output and the hidden state\n",
        "    return out, hidden\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    ''' Initializes hidden state '''\n",
        "    # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "    # initialized to zero, for hidden state and cell state of LSTM\n",
        "    weight = next(self.parameters()).data\n",
        "    \n",
        "    if (train_on_gpu):\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "    else:\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfu9TW6AxHgz",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yImCgnQxbzU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainLSTM(net, data, epochs=10, batch_size=10, \n",
        "          seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "    ''' Training a network \n",
        "    \n",
        "        Arguments\n",
        "        ---------\n",
        "        \n",
        "        net:        CharRNN network\n",
        "        data:       text data to train the network\n",
        "        epochs:     Number of epochs to train\n",
        "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
        "        seq_length: Number of character steps per mini-batch\n",
        "        lr:         learning rate\n",
        "        clip:       gradient clipping\n",
        "        val_frac:   Fraction of data to hold out for validation\n",
        "        print_every:   Number of steps for printing training and validation loss\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # Change the network mode into train\n",
        "    net.train()\n",
        "    \n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # create training and validation data\n",
        "    val_idx = int(len(data)*(1-val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        # initialize hidden state\n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "            # One-hot encode our data and make them Torch tensors\n",
        "            x = one_hot_encode(x, n_chars)\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            \n",
        "            if(train_on_gpu):\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # zero accumulated gradients\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # get the output from the model\n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            # calculate the loss and perform backprop\n",
        "            loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "            loss.backward()\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            opt.step()\n",
        "            \n",
        "            # loss stats\n",
        "            if counter % print_every == 0:\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVh8-QpAGrGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateLSTM():\n",
        "  # Get validation loss\n",
        "  val_h = net.init_hidden(batch_size)\n",
        "  val_losses = []\n",
        "  net.eval()\n",
        "  for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "      # One-hot encode our data and make them Torch tensors\n",
        "      x = one_hot_encode(x, n_chars)\n",
        "      x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "      # Creating new variables for the hidden state, otherwise\n",
        "      # we'd backprop through the entire training history\n",
        "      val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "      inputs, targets = x, y\n",
        "      if(train_on_gpu):\n",
        "          inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "      output, val_h = net(inputs, val_h)\n",
        "      val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "\n",
        "      val_losses.append(val_loss.item())\n",
        "\n",
        "  net.train() # reset to train mode after iterationg through validation data\n",
        "\n",
        "  print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "        \"Step: {}...\".format(counter),\n",
        "        \"Loss: {:.4f}...\".format(loss.item()),\n",
        "        \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-o4zcalthqw",
        "colab_type": "text"
      },
      "source": [
        "## 4.3. Instantiate the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0qPmnPBbzXS",
        "colab_type": "code",
        "outputId": "5ba80064-efbc-4834-b1bb-e076532ee4f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# define and print the net\n",
        "n_hidden=512\n",
        "n_layers=2\n",
        "\n",
        "net = CharRNN(chars, n_hidden, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CharRNN(\n",
            "  (lstm): LSTM(127, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5)\n",
            "  (fc): Linear(in_features=512, out_features=127, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jNJhDt5tmND",
        "colab_type": "code",
        "outputId": "604c1ba4-20bf-4f0b-8f88-710345b7d14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "batch_size = 64\n",
        "seq_length = 64\n",
        "n_epochs = 2 # start smaller if you are just testing initial behavior\n",
        "encoded = np.array([net.char2int[ch] for ch in text])\n",
        "\n",
        "# train the model\n",
        "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2... Step: 10... Loss: 3.4181... Val Loss: 3.3141\n",
            "Epoch: 1/2... Step: 20... Loss: 3.3590... Val Loss: 3.2516\n",
            "Epoch: 1/2... Step: 30... Loss: 3.2768... Val Loss: 3.2388\n",
            "Epoch: 1/2... Step: 40... Loss: 3.2683... Val Loss: 3.2386\n",
            "Epoch: 1/2... Step: 50... Loss: 3.2602... Val Loss: 3.2348\n",
            "Epoch: 1/2... Step: 60... Loss: 3.2523... Val Loss: 3.2340\n",
            "Epoch: 1/2... Step: 70... Loss: 3.2816... Val Loss: 3.2321\n",
            "Epoch: 1/2... Step: 80... Loss: 3.3397... Val Loss: 3.2282\n",
            "Epoch: 1/2... Step: 90... Loss: 3.2199... Val Loss: 3.2212\n",
            "Epoch: 1/2... Step: 100... Loss: 3.2861... Val Loss: 3.1993\n",
            "Epoch: 1/2... Step: 110... Loss: 3.1949... Val Loss: 3.1707\n",
            "Epoch: 1/2... Step: 120... Loss: 3.1606... Val Loss: 3.1106\n",
            "Epoch: 1/2... Step: 130... Loss: 3.0554... Val Loss: 3.0130\n",
            "Epoch: 1/2... Step: 140... Loss: 2.9939... Val Loss: 2.9477\n",
            "Epoch: 1/2... Step: 150... Loss: 2.9598... Val Loss: 2.8377\n",
            "Epoch: 1/2... Step: 160... Loss: 2.8123... Val Loss: 2.7311\n",
            "Epoch: 1/2... Step: 170... Loss: 2.7622... Val Loss: 2.6412\n",
            "Epoch: 1/2... Step: 180... Loss: 2.6059... Val Loss: 2.5932\n",
            "Epoch: 1/2... Step: 190... Loss: 2.5716... Val Loss: 2.5322\n",
            "Epoch: 1/2... Step: 200... Loss: 2.5707... Val Loss: 2.4970\n",
            "Epoch: 1/2... Step: 210... Loss: 2.5434... Val Loss: 2.4518\n",
            "Epoch: 1/2... Step: 220... Loss: 2.5131... Val Loss: 2.4099\n",
            "Epoch: 1/2... Step: 230... Loss: 2.5138... Val Loss: 2.3833\n",
            "Epoch: 1/2... Step: 240... Loss: 2.5105... Val Loss: 2.3569\n",
            "Epoch: 1/2... Step: 250... Loss: 2.4193... Val Loss: 2.3457\n",
            "Epoch: 1/2... Step: 260... Loss: 2.3780... Val Loss: 2.3198\n",
            "Epoch: 2/2... Step: 270... Loss: 2.3619... Val Loss: 2.3005\n",
            "Epoch: 2/2... Step: 280... Loss: 2.3813... Val Loss: 2.2824\n",
            "Epoch: 2/2... Step: 290... Loss: 2.3946... Val Loss: 2.2634\n",
            "Epoch: 2/2... Step: 300... Loss: 2.3335... Val Loss: 2.2522\n",
            "Epoch: 2/2... Step: 310... Loss: 2.3351... Val Loss: 2.2376\n",
            "Epoch: 2/2... Step: 320... Loss: 2.3330... Val Loss: 2.2229\n",
            "Epoch: 2/2... Step: 330... Loss: 2.3054... Val Loss: 2.2138\n",
            "Epoch: 2/2... Step: 340... Loss: 2.2789... Val Loss: 2.2044\n",
            "Epoch: 2/2... Step: 350... Loss: 2.2769... Val Loss: 2.1931\n",
            "Epoch: 2/2... Step: 360... Loss: 2.2726... Val Loss: 2.1773\n",
            "Epoch: 2/2... Step: 370... Loss: 2.2323... Val Loss: 2.1686\n",
            "Epoch: 2/2... Step: 380... Loss: 2.2458... Val Loss: 2.1570\n",
            "Epoch: 2/2... Step: 390... Loss: 2.2169... Val Loss: 2.1487\n",
            "Epoch: 2/2... Step: 400... Loss: 2.2475... Val Loss: 2.1386\n",
            "Epoch: 2/2... Step: 410... Loss: 2.1781... Val Loss: 2.1285\n",
            "Epoch: 2/2... Step: 420... Loss: 2.2222... Val Loss: 2.1182\n",
            "Epoch: 2/2... Step: 430... Loss: 2.2070... Val Loss: 2.1121\n",
            "Epoch: 2/2... Step: 440... Loss: 2.1891... Val Loss: 2.1053\n",
            "Epoch: 2/2... Step: 450... Loss: 2.1961... Val Loss: 2.0965\n",
            "Epoch: 2/2... Step: 460... Loss: 2.1663... Val Loss: 2.0897\n",
            "Epoch: 2/2... Step: 470... Loss: 2.1282... Val Loss: 2.0847\n",
            "Epoch: 2/2... Step: 480... Loss: 2.1856... Val Loss: 2.0762\n",
            "Epoch: 2/2... Step: 490... Loss: 2.2010... Val Loss: 2.0714\n",
            "Epoch: 2/2... Step: 500... Loss: 2.1661... Val Loss: 2.0648\n",
            "Epoch: 2/2... Step: 510... Loss: 2.1494... Val Loss: 2.0584\n",
            "Epoch: 2/2... Step: 520... Loss: 2.1358... Val Loss: 2.0521\n",
            "Epoch: 2/2... Step: 530... Loss: 2.1639... Val Loss: 2.0471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LIk3kaStzBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(rnn, char, h=None, top_k=None):\n",
        "  ''' Given a character, predict the next character.\n",
        "      Returns the precited character and the hidden state.\n",
        "  '''\n",
        "  \n",
        "  # tensor inputs\n",
        "  x = np.array([[rnn.char2int[char]]])\n",
        "  x = one_hot_encode(x, len(rnn.chars))\n",
        "  inputs = torch.from_numpy(x)\n",
        "  \n",
        "  if(train_on_gpu):\n",
        "    inputs  = inputs.cuda()\n",
        "  \n",
        "  # detach hidden state from history\n",
        "  h = tuple([each.data for each in h])\n",
        "  # get the output of the model\n",
        "  out, h = net(inputs, h)\n",
        "  \n",
        "  # get the character probabilities\n",
        "  p = F.softmax(out, dim=1).data\n",
        "  if(train_on_gpu):\n",
        "    p = p.cpu() # move to cpu\n",
        "  \n",
        "  # get top characters\n",
        "  if top_k is None:\n",
        "    top_ch = np.arange(len(net.chars))\n",
        "  else:\n",
        "    p, top_ch = p.topk(top_k) # topk gets top likely next characters\n",
        "    top_ch = top_ch.numpy().squeeze()\n",
        "    \n",
        "  # select the likely next character with some element of randomness\n",
        "  p = p.numpy().squeeze()\n",
        "  char = np.random.choice(top_ch, p=p/p.sum())\n",
        "  \n",
        "  # return the encoded value of the predicted char and the hidden state\n",
        "  return net.int2char[char], h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSxSszzjE5UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(net, size, prime='байна', top_k=None):\n",
        "  \n",
        "  if(train_on_gpu):\n",
        "    net.cuda()\n",
        "  else:\n",
        "    net.cpu()\n",
        "    \n",
        "  net.eval() # eval mode\n",
        "  \n",
        "  # First off, run through the prime characters\n",
        "  chars = [ch for ch in prime]\n",
        "  h = net.init_hidden(1)\n",
        "  for ch in prime:\n",
        "    char, h = predict(net, ch, h, top_k=top_k)\n",
        "    \n",
        "  chars.append(char)\n",
        "  \n",
        "  # Now pass in the previous character and get a new one\n",
        "  for ii in range(size):\n",
        "    char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "    chars.append(char)\n",
        "    \n",
        "  return ''.join(chars)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMvFQuxaGcnD",
        "colab_type": "code",
        "outputId": "960e4909-0f1e-4a8c-a376-4be2bd4f5d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(sample(net, 100, \"өгүүллэг\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "өгүүллэгсэн түүнээт - Тэгээ! Тадан ергөхөт сондой холмой тээ? амга өлөөс ч чимь\n",
            "чана. Ачиж шолтой сууг нь уул\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ZnWmbSHHx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}